[["index.html", "Volleyball analytics snippets 1 Introduction openvolley Contributing 1.1 Contributors and acknowledgements", " Volleyball analytics snippets Ben Raymond, Adrien Ickowicz 1 Introduction This document provides some code snippets and guidance that might help you with volleyball analytics in R, and in particular with the openvolley family of packages. openvolley The openvolley project aims to provide an open-source, freely available software ecosystem to support volleyball analytics. It consists of a family of add-on packages that can be used with the R software package. R provides an enormous range of data manipulation, analysis, modelling, and graphical display functionality, including the ability to build interactive data analysis and visualisation apps. See http://openvolley.org. Contributing Have some code or corrections that you’d like to contribute to this project? Or a request for something you’d like to see covered? Please join in! Either: fork the GitHub repository, create a new branch with your changes, and submit a pull request; or open an issue (especially for requests); or contact the maintainers directly. Maintainers and contributors must follow this project’s code of conduct. Contribution guidelines if you are forking the repo and submitting a pull request, please create a new branch and make your changes there please follow the existing code styling and conventions existing examples typically use tidyverse functions (e.g. using x %&gt;% dplyr::filter(blah) rather than direct dataframe-indexing like x[blah, ]) — but base R code is perfectly fine too, particularly if it’s easier to understand if your code example should actually run and show an output, use x and/or px as your data inputs if possible. These are from the example file bundled with the datavolley package: x &lt;- dv_read(dv_example_file()) px &lt;- plays(x) Note that this example file does not have some information scouted (e.g. attack or serve coordinates). be aware that the project maintainers might modify your code to better fit the existing code style and document structure. 1.1 Contributors and acknowledgements "],["setup.html", "2 Setup 2.1 Example data", " 2 Setup Install some volleyball-specific packages from the openvolley project: options(repos = c(openvolley = &quot;https://openvolley.r-universe.dev&quot;, CRAN = &quot;https://cloud.r-project.org&quot;)) install.packages(c(&quot;datavolley&quot;, &quot;ovlytics&quot;)) VBStats users will additionally need the peranavolley package: install.packages(&quot;peranavolley&quot;) 2.1 Example data Load some data that we’ll use in this document for illustrative purposes (a match between GKS Katowice and MKS Bedzin during the 2018/19 Polish Plus Liga, file courtesy Mark Lebedew): x &lt;- dv_read(ovdata::ovdata_example(&quot;190301_kats_beds&quot;)) px &lt;- plays(x) summary(x) #&gt; Match summary: #&gt; Date: 2019-01-03 #&gt; League: Plus Liga 2018/2019 - Plus Liga 2018/20189- Faza Zasadnicza #&gt; Teams: GKS Katowice (Gruszka Piotr/Słaby Grzegorz) #&gt; vs #&gt; MKS Będzin (Siewiorek Emil) #&gt; Result: 3-2 (25-20, 18-25, 25-15, 19-25, 15-6) #&gt; Duration: 114 minutes "],["reading-files.html", "3 Reading files 3.1 DataVolley 3.2 VBStats 3.3 Reading multiple files", " 3 Reading files 3.1 DataVolley library(datavolley) filename &lt;- &quot;c:/my/filename.dvw&quot; x &lt;- dv_read(filename) The dv_read function has a number of optional parameters. The most important are probably: insert_technical_timeouts. By default, technical timeouts will be inserted at points 8 and 16 of sets 1–4 (for indoor files) or when the team scores sum to 21 in sets 1–2 (beach). You can avoid inserting technical timeouts by setting this to FALSE, or change the scores at which TTs are inserted (see dv_read function help) skill_evaluation_decode. By default, dv_read uses the standard DataVolley scouting conventions. This controls the interpretation of the evaluation codes (e.g. B/ is a block invasion (net touch or other violation)). However, not all scouts use these conventions. VolleyMetrics, for example, use B/ to mean a poor block that the opposition can replay (amongst other convention differences). In Germany, B/ is usually used to indicate a block tool (attack off the block for a kill) and B= is used to indicate an invasion. You can tell the dv_read function to follow these conventions by dv_read(..., skill_evaluation_decode = \"volleymetrics\") or dv_read(..., skill_evaluation_decode = \"german\"). If your files use other scouting conventions, you can write your own decoder (see dv_read function help) date_format. Dates can be ambiguous in DataVolley files, and sometimes they will be parsed incorrectly (e.g. swapping month and day). If the dates in your files are being read incorrectly you can set the expected format, e.g. dv_read(..., date_format = \"dmy\") or dv_read(..., date_format = \"mdy\"). encoding specifies the text encoding of the file. By default this will be guessed, but if the text encoding is guessed incorrectly then player/team names might appear garbled (e.g. accented characters wrong) and in extreme cases the file might refuse to read altogether. You can get an idea of what is going on with text encoding by asking for verbose output: dv_read(..., verbose = TRUE). You can set the text encoding by e.g. dv_read(..., encoding = \"windows-1252\") 3.2 VBStats library(peranavolley) x &lt;- pv_read(&quot;c:/my/filename.psvb&quot;) 3.3 Reading multiple files You might want to read multiple files in and analyze them all together. First find all of the DataVolley files in the target directory: d &lt;- dir(&quot;c:/data&quot;, pattern = &quot;dvw$&quot;, full.names = TRUE) ## if your files are in nested directories, add &#39;recursive = TRUE&#39; to the arguments Read all of those files in a loop, extract the play-by-play component from each, and then join of those all together: lx &lt;- list() ## read each file for (fi in seq_along(d)) lx[[fi]] &lt;- dv_read(d[fi], insert_technical_timeouts = FALSE) ## now extract the play-by-play component from each and bind them together px &lt;- list() for (fi in seq_along(lx)) px[[fi]] &lt;- plays(lx) px &lt;- do.call(rbind, px) Note, the idiomatic R way to do this would be to use lapply instead of for loops: lx &lt;- lapply(d, dv_read, insert_technical_timeouts = FALSE) px &lt;- do.call(rbind, lapply(lx, plays)) It achieves the same thing. Use whichever you prefer. Similarly, you could also use dplyr’s bind_rows function instead of do.call(rbind, ...): library(dplyr) px &lt;- bind_rows(lapply(lx, plays)) After these operations, we have lx, which is a list containing the full contents of every match file (including the match and team metadata), and px, which is just the play-by-play component of each (but all joined together, which makes it easy to analyze multiple matches at once). "],["file-validation.html", "4 File validation", " 4 File validation Check the messages component of a datavolley or peranavolley object for the results of file validation and checking. This can help improve the consistency of your files and therefore of any subsequent analyses that you might conduct. x &lt;- dv_read(dv_example_file(2)) x$messages file_line_number video_time message file_line NA NA Home team (ACH Volley) player Daniel Lewis has no position (opposite/outside/etc) assigned in the players list NA 16 NA The date of the match (2012-12-28) is more than 10 years ago, is it correct? 12/28/2012;20.00.00;2012/2013;1. DOL Radenska Classic - Pokal moški;Semifinals - Pokal SLO - mo?;;1;PM06;1;1;Z;0; 107 NA Consecutive actions by the same player a08AM-;;r;;;;;20.13.39;1;6;6;;;;8;10;6;1;16;15;7;1;14;8;4;5; 183 NA Unexpected skill type: N for skill: S *01SN!;;;;;;;20.21.01;1;3;3;;;;1;16;15;8;10;6;15;4;5;7;1;14; 184 NA Unexpected skill type: N for skill: R a15RN+;;;;;;;20.21.01;1;3;3;;;;1;16;15;8;10;6;15;4;5;7;1;14; 233 NA Consecutive actions by the same player a07AM-;;r;;;;;20.25.58;1;5;5;;;;10;6;1;16;15;8;1;14;15;4;5;7; 270 NA Consecutive actions by the same player *01AH-;;r;;;;;20.28.44;1;4;3;;;;6;1;16;15;8;10;15;2;5;17;1;14; 291 NA Consecutive actions by the same player a15AM#;s;r;;;;;20.33.03;2;1;2;;;;15;8;10;6;1;16;4;5;17;1;14;15; 304 NA Consecutive actions by the same player a15AM#;s;r;;;;;20.33.57;2;6;1;;;;8;10;6;1;16;15;5;17;1;14;15;4; 314 NA Consecutive actions by the same player a17AM-;;r;;;;;20.34.41;2;5;6;;;;10;6;1;16;15;8;17;1;14;15;4;5; 344 NA Consecutive actions by the same player *01AM#;s;r;;;;;20.36.43;2;5;5;;;;10;6;1;16;15;8;1;14;15;4;5;17; 357 NA Consecutive actions by the same player *08AM#;s;r;;;;;20.37.47;2;4;4;;;;6;1;16;15;8;10;14;15;4;5;17;1; 379 NA Consecutive actions by the same player a17AM/;p;r;;;;;20.40.37;2;2;3;;;;16;15;8;10;6;1;15;4;5;17;1;14; 564 NA Consecutive actions by the same player a07AH/;p;r;;;;;20.59.39;3;1;1;;;;15;8;10;6;1;16;5;7;1;14;15;4; 576 NA Consecutive actions by the same player a07AM-;;r;;;;;21.01.22;3;1;1;;;;15;8;10;6;1;16;5;7;1;14;15;4; 583 NA Consecutive actions by the same player a07AM-;;r;;;;;21.01.44;3;1;1;;;;15;8;10;6;1;16;5;7;1;14;15;4; 615 NA Rally had ball contacts but no serve *15EM#;;;;;;;21.05.25;3;6;6;;;;8;10;6;1;16;15;7;1;14;15;4;5; 617 NA Block by a back-row player a07BM+;;;;;;;21.05.44;3;6;6;;;;8;10;6;1;16;15;7;1;14;15;4;5; 663 NA Rally does not include a winning or losing action *p17:07;;;;;;;21.10.01;3;3;2;;;;1;16;15;8;10;6;2;5;7;1;14;15; 691 NA Repeated row with same skill and evaluation_code for the same player *08AM-;;s;;;;;21.12.15;3;2;1;;;;16;15;8;10;6;1;6;7;1;14;15;2; Note that not all warnings will necessarily correspond to actual scouting errors. This particular file was scouted without all actions (in particular, not all setting actions). The warnings about “Consecutive actions by the same player” are to do with a player receiving or digging the ball and then making the next attack (but the intervening set action was not scouted). This probably doesn’t matter, so long as you are aware of this when analyzing the files. "],["general-notes-and-tips.html", "5 General notes and tips", " 5 General notes and tips It may be better to use the evaluation column instead of the evaluation_code column for filtering and other data operations Different scouting conventions mean that the entries in the evaluation_code column don’t always mean the same thing. For example, a block scouted as B/ is an invasion (net touch or other violation) according to the default DataVolley conventions, but some scouts instead use B/ to indicate a block tool, and others use it to indicate a poor block back to the opposition team. When a file is read into R with dv_read, the evaluation codes are converted into strings (stored in the evaluation column) following the conventions specified by the skill_evaluation_decode argument. Using the evaluation column is therefore likely to be more robust than the evaluation_code column, especially if your code is to be used on files collected by different scouts. For example, find block invasions by px %&gt;% dplyr::filter(skill == &quot;Block&quot; &amp; evaluation == &quot;Invasion&quot;) rather than by px %&gt;% dplyr::filter(skill == &quot;Block&quot; &amp; evaluation_code == &quot;/&quot;) Identifiers There are a number of columns in the play-by-play data that are useful to identify different aspects of play match_id uniquely identifies the match set_number is the set number (1–5) within a match. If you want to uniquely identify a particular set (from amongst many matches) use the combination of match_id and set_number point_id identifies the rally number (point) within a match. Each rally (point) begins with a serve (or rotation fault). Timeouts and other non-action points might have their own point_id, so don’t rely on point_id values being consecutive from one rally to the next. point_id values are only unique within a match (so e.g. two different matches will both have a point with point_id value of 1 team_touch_id identifies the touches that a team makes while the ball is on their side of the net. So a serve will have a certain team_touch_id, then the reception, set, and attack made by the receiving team will all have the same team_touch_id (different to the serve’s team_touch_id). The following block, dig, set, and attack will have another team_touch_id, and so on. team_touch_id values are also only unique within a match the phase column identifies the phase of play: it can take the values Serve, Reception, or Transition. Note that a block made against a reception attack (the attack made by the receiving team immediately after receiving the serve) is considered to be Reception phase, but the dig made by the blocking team immediately after that (and every subsequent action in the rally) are Transition "],["data-augmentation.html", "6 Data augmentation 6.1 The setter of a given attack 6.2 Setter player IDs 6.3 Reception quality", " 6 Data augmentation Some examples of adding extra columns to our play-by-play data in order to support particular analyses, or to make other data-wrangling tasks easier. 6.1 The setter of a given attack Aim: Identify the player who made the set associated with each attack (noting that some files might not have the setting action coded for all attacks, or even coded at all). px &lt;- px %&gt;% mutate(set_player_id = case_when(skill == &quot;Attack&quot; &amp; lag(skill) == &quot;Set&quot; &amp; team == lag(team) ~ lag(player_id)) (The set_player_id column will be NA when there is no matching set coded before the attack.) 6.2 Setter player IDs Aim: identify the player_id of the setter on court for each data row. The play-by-play data frame has home_player_id1, home_player_id2, …, home_player_id6, which give the player_id of the home team player currently in position 1, 2, …, and 6. It also has a home_setter_position column, which tells us which position the home team setter is in (1–6). So to create a home_setter_id column we simply need to extract the value in the home_player_idX column for each row of the data frame, where X is the value in the home_setter_position at each row. One way to do this is: px &lt;- px %&gt;% mutate(home_setter_id = case_when(home_setter_position == 1 ~ home_player_id1, home_setter_position == 2 ~ home_player_id2, home_setter_position == 3 ~ home_player_id3, home_setter_position == 4 ~ home_player_id4, home_setter_position == 5 ~ home_player_id5, home_setter_position == 6 ~ home_player_id6)) But that is rather cumbersome and inelegant. A more concise method is: px &lt;- px %&gt;% rowwise() %&gt;% mutate(home_setter_id = cur_data()[[paste0(&quot;home_player_id&quot;, home_setter_position)]]) %&gt;% ungroup 6.3 Reception quality Aim: add a column that tells us the reception quality associated with each rally. The reception quality for a given rally is found in the evaluation column of the row that has the skill value of “Reception”. We just need to propagate this value to all other rows associated with that particular rally. First we extract the reception quality for each rally (remember from the Identifiers section that the point_id value identifies the rally, but needs to be combined with match_id to be globally unique): rq &lt;- px %&gt;% dplyr::filter(skill == &quot;Reception&quot;) %&gt;% group_by(match_id, point_id) %&gt;% dplyr::summarize(reception_quality = if (n() == 1) .data$evaluation else NA_character_) %&gt;% ungroup So rq is a data.frame with the reception quality for each match_id and point_id combination. reception_quality will be NA if there was no reception (or more than one reception — perhaps due to a scouting error?) involved in that point. Now join rq back to our full plays dataframe: px &lt;- px %&gt;% left_join(rq, by = c(&quot;match_id&quot;, &quot;point_id&quot;)) So now we have reception_quality for all rows of the data frame. "],["filtering-and-subsetting.html", "7 Filtering and subsetting 7.1 Attack after perfect or good reception 7.2 Players on court 7.3 First transition attack", " 7 Filtering and subsetting Some different examples of extracting particular parts of the play-by-play data. 7.1 Attack after perfect or good reception Aim: find attacks after perfect or good reception In the Reception quality section, we added a reception_quality column to our data frame. We can use this now to identify reception-phase attacks, in rallies where reception was good or perfect: px %&gt;% dplyr::filter(skill == &quot;Attack&quot; &amp; phase == &quot;Reception&quot; &amp; grepl(&quot;Perfect|Positive&quot;, reception_quality)) %&gt;% group_by(team) %&gt;% dplyr::summarize(kill_rate = mean(evaluation == &quot;Winning attack&quot;)) #&gt; # A tibble: 2 × 2 #&gt; team kill_rate #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 GKS Katowice 0.636 #&gt; 2 MKS Będzin 0.585 7.2 Players on court Aim: to extract the subset of our plays dataframe that correspond to points where particular players were on court. First some helper functions: ## find rows where a single player is on court player_on_court &lt;- function(x, target_player_id, team = NULL) { if (!is.null(team)) team &lt;- match.arg(team, c(&quot;home&quot;, &quot;visiting&quot;)) ## &#39;team&#39; is optional here, if NULL then we look at both home and visiting teams idx &lt;- rep(FALSE, nrow(x)) if (is.null(team) || team == &quot;home&quot;) { idx &lt;- idx | x$home_player_id1 == target_player_id | x$home_player_id2 == target_player_id | x$home_player_id3 == target_player_id | x$home_player_id4 == target_player_id | x$home_player_id5 == target_player_id | x$home_player_id6 == target_player_id } if (is.null(team) || team == &quot;visiting&quot;) { idx &lt;- idx | x$visiting_player_id1 == target_player_id | x$visiting_player_id2 == target_player_id | x$visiting_player_id3 == target_player_id | x$visiting_player_id4 == target_player_id | x$visiting_player_id5 == target_player_id | x$visiting_player_id6 == target_player_id } idx[is.na(idx)] &lt;- FALSE idx } ## find rows where any of our target players are on court any_player_on_court &lt;- function(x, target_player_ids, team = NULL) { ## for each target player, find rows where they are on court out &lt;- lapply(target_player_ids, function(pid) player_on_court(x, target_player_id = pid, team = team)) ## and now find rows where ANY of those players were on court apply(do.call(cbind, out), 1, any) } ## find rows where all of our target players are on court all_players_on_court &lt;- function(x, target_player_ids, team = NULL) { ## for each target player, find rows where they are on court out &lt;- lapply(target_player_ids, function(pid) player_on_court(x, target_player_id = pid, team = team)) ## and now find rows where ALL of those players were on court apply(do.call(cbind, out), 1, all) } And then we can apply these functions, for example to find rows when both of the players with id BR5 and BR10 are on court: nrow(px) ## the number of rows in the full dataframe #&gt; [1] 1652 my_target_player_ids &lt;- c(&quot;BR5&quot;, &quot;BR10&quot;) px2 &lt;- px[all_players_on_court(px, my_target_player_ids), ] nrow(px2) ## the number of rows in the filtered dataframe #&gt; [1] 0 7.3 First transition attack Aim: find rows corresponding to the first transition attack opportunity in each rally (i.e. after the receiving team has attacked, find the first attack by the serving team). As noted in the Identifiers setion, each team’s dig-set-attack (or whatever touches they make on their side of the net) has a unique team_touch_id value. First we find the team_touch_id values for reception-phase play, and then add one to each to get the next team touch (i.e. the first transition play, by the other team — but note that this next touch also has to be part of the same point, so we keep track of point_id too): ttid &lt;- px %&gt;% dplyr::filter(skill == &quot;Reception&quot;) %&gt;% distinct(match_id, point_id, team_touch_id) %&gt;% mutate(team_touch_id = team_touch_id+1, is_fta = TRUE) ## join this to px px &lt;- px %&gt;% left_join(ttid, by = c(&quot;match_id&quot;, &quot;point_id&quot;, &quot;team_touch_id&quot;)) %&gt;% mutate(is_fta = case_when(is.na(is_fta) ~ FALSE, TRUE ~ is_fta)) ## clean up the NAs The px$is_fta column should be TRUE for all actions that are in first-transition play, and you can extract what you need from that (filter just the attacks, or whatever you need). "],["indicators-and-statistics.html", "8 Indicators and statistics 8.1 Expected sideout rate 8.2 Expected breakpoint rate 8.3 Set assist rate", " 8 Indicators and statistics 8.1 Expected sideout rate It is common to see passer performance reported as a single number bsaed on pass ratings, using a weighting scheme to combine them. For example, a perfect pass might be worth 3 points, an “OK” pass 2 points, a poor pass 1 point, and an error 0 points. Then a passer who passed one perfect pass, one poor pass, and one error would have a performance rating of (3 + 1 + 0)/3 = 1.333. However, the weightings used in this type of approach are often arbitrary (why should a perfect pass be 3 times as valuable as a poor pass?) Expected sideout rate uses pass ratings to evaluate passing performance, but with a more principled approach to assigning the value of the different pass outcomes. It weights each pass rating according to the league-average sideout rate associated with it. For example, if the league-average sideout rate on a perfect pass is 75%, and the league-average sideout rate on a poor pass is 50%, then a perfect pass should be worth 75/50 = 1.5 times as much as a poor pass. We can implement this by first calculating the league-average sideout rate on each pass rating, using a reference data set which is usually a whole-league data set or similar (note that in this example, purely for convenience, we are using data px from a single match as its own reference. This is generally not a good idea, as noted below): lso &lt;- px %&gt;% dplyr::filter(skill == &quot;Reception&quot;) %&gt;% group_by(.data$evaluation) %&gt;% dplyr::summarize(expected_sideout_rate = mean(.data$team == .data$point_won_by, na.rm = TRUE)) %&gt;% ungroup This tells us the relative value of each pass rating: lso #&gt; # A tibble: 6 × 2 #&gt; evaluation expected_sideout_rate #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Error 0 #&gt; 2 Negative, limited attack 0.512 #&gt; 3 OK, no first tempo possible 0.444 #&gt; 4 Perfect pass 0.808 #&gt; 5 Poor, no attack 0 #&gt; 6 Positive, attack 0.688 (As a side note — you can see that in this case an “OK” pass (e.g. a pass on the 3m line) has a value of 0.44, which is lower than the value of a negative pass (a poorer pass than an “OK” one — value 0.51). This is because we are using only a single match as our reference data set, and it just so happens that in this particular match the sideout rate on negative passes was better than on OK passes. With a larger reference data set from many matches, these types of inconsistencies will be greatly reduced.) Then we can join our lso data back to our target px data set, creating an expected_sideout_rate value associated with each pass. The overall expected sideout rate for a given player or team is then just the average of the expected_sideout_rate values of all of their passes: px %&gt;% dplyr::filter(.data$skill == &quot;Reception&quot;) %&gt;% left_join(lso, by = &quot;evaluation&quot;) %&gt;% group_by(.data$player_id, .data$player_name) %&gt;% dplyr::summarize(n_receptions = n(), expected_sideout_rate = mean(.data$expected_sideout_rate, na.rm = TRUE)) %&gt;% ungroup #&gt; # A tibble: 9 × 4 #&gt; player_id player_name n_receptions expected_sideout_rate #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 162 Jakub Peszko 3 0.647 #&gt; 2 164 Bartosz Mariański 27 0.545 #&gt; 3 231 Adrian Buchowski 28 0.536 #&gt; 4 30341 Tomas Rousseaux 21 0.543 #&gt; 5 30511 Jake Langlois 29 0.470 #&gt; 6 420 Lukas Tichacek 2 0.512 #&gt; 7 456 Rafał Sobański 25 0.549 #&gt; 8 561 Marcin Komenda 1 0 #&gt; 9 656 Michał Potera 24 0.649 8.2 Expected breakpoint rate An analogous approach can be used to calculate expected breakpoint rate, as a measure of serving performance. lbp &lt;- px %&gt;% dplyr::filter(skill == &quot;Serve&quot;) %&gt;% group_by(.data$evaluation) %&gt;% dplyr::summarize(expected_breakpoint_rate = mean(.data$team == .data$point_won_by, na.rm = TRUE)) %&gt;% ungroup And px %&gt;% dplyr::filter(.data$skill == &quot;Serve&quot;) %&gt;% left_join(lbp, by = &quot;evaluation&quot;) %&gt;% group_by(.data$player_id, .data$player_name) %&gt;% dplyr::summarize(n_serves = n(), expected_breakpoint_rate = mean(.data$expected_breakpoint_rate, na.rm = TRUE)) %&gt;% ungroup #&gt; # A tibble: 19 × 4 #&gt; player_id player_name n_serves expected_breakpoint_rate #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 162 Jakub Peszko 1 0 #&gt; 2 172 Wojciech Sobala 2 0.270 #&gt; 3 22529 Rafał Faryna 11 0.364 #&gt; 4 22531 Bartłomiej Grzechnik 13 0.319 #&gt; 5 22706 Maciej Fijałek 1 0.270 #&gt; 6 231 Adrian Buchowski 15 0.480 #&gt; 7 235 Tomasz Kowalski 2 0.244 #&gt; 8 29752 Dawid Woch 2 0.488 #&gt; 9 29886 Emanuel Kohut 15 0.313 #&gt; 10 30341 Tomas Rousseaux 16 0.374 #&gt; 11 30511 Jake Langlois 11 0.264 #&gt; 12 420 Lukas Tichacek 22 0.392 #&gt; 13 433 Bartosz Krzysiek 7 0.377 #&gt; 14 450 Artur Ratajczak 13 0.461 #&gt; 15 456 Rafał Sobański 13 0.399 #&gt; 16 488 Karol Butryn 15 0.376 #&gt; 17 516 Bartłomiej Krulicki 20 0.437 #&gt; 18 561 Marcin Komenda 11 0.363 #&gt; 19 632 Jan Fornal 3 0.325 8.3 Set assist rate The assist rate is the proportion of sets that yield an attack kill. The lead function from the dplyr package helps here, allowing us to augment the “set” data rows with the outcome of the associated attack (which will be in the data row following the set data row): ## first add a variable indicating whether a set was followed by a kill by the same team px %&gt;% mutate(set_had_attack_kill = .data$skill == &quot;Set&quot; &amp; lead(.data$skill) == &quot;Attack&quot; &amp; lead(.data$evaluation) == &quot;Winning attack&quot; &amp; lead(.data$team) == .data$team) %&gt;% ## then filter to just set rows filter(.data$skill == &quot;Set&quot;) %&gt;% ## and summarize as desired group_by(.data$team, .data$phase) %&gt;% dplyr::summarize(assist_rate = sum(set_had_attack_kill, na.rm = TRUE) / n()) #&gt; # A tibble: 4 × 3 #&gt; # Groups: team [2] #&gt; team phase assist_rate #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 GKS Katowice Reception 0.431 #&gt; 2 GKS Katowice Transition 0.478 #&gt; 3 MKS Będzin Reception 0.429 #&gt; 4 MKS Będzin Transition 0.355 Note that this relies on all set and attack actions being scouted (i.e. there is a row in our px data frame for every set, as well as for every attack. Some scouts do not record all ball touches — digs and sets are the most commonly-omitted skills.) "],["court-plots.html", "9 Court plots 9.1 Background on location information 9.2 Plotting by zone or subzone 9.3 Plotting by cone 9.4 Plotting by line segment 9.5 Heatmaps 9.6 Changing direction 9.7 Plotting mid-coordinates", " 9 Court plots 9.1 Background on location information 9.1.1 Zones and subzones Scouts using DataVolley make use of zones (and optionally subzones) for all skills. Cones can alternatively be used for attack directions (instead of recording the end zone). Attacks cannot be scouted with both zones and cones in one file, DataVolley supports only one or the other. The zone/cone associated with each action is stored in the DataVolley file as the zone/cone number, without any inherent direction (side of the court) and without any actual location information. To plot the location of an action on a court diagram, we first generate actual court coordinates using the dv_xy() function. We pass it the zone number and which end of the court diagram (upper or lower) we wish to plot onto — let’s say an action from zone 4: dv_xy(zones = 4, end = &quot;lower&quot;) #&gt; x y #&gt; 1 1 3 So zone 4 is located at x = 1 and y = 3. The coordinate system used by openvolley packages looks like this: 9.1.2 Coordinates Actions can also be scouted with coordinates (the more precise locations, that are entered with the mouse click on the small court diagram). These are stored separately to the zone information in the DataVolley file. Coordinates can be used alongside of zones or cones, but not all scouts use coordinates. Coordinates are stored in the file as a single index from 1-10000, where 1 starts in the bottom-left on the lower side of the court diagram, across the row to 100 at the bottom-right, and it fills row-wise until 9901 is the top-left on the upper side of the court diagram and 10000 is the top-right. That covers both sides of the court, so coordinates are stored in the dvw file with an actual court location (and side) associated with them. When a DataVolley file is read into R using dv_read, these coordinates are stored without alteration in the start_coordinate, mid_coordinate, and end_coordinate columns. They are also converted to the same reference system shown above (using the dv_index2xy() function), and these values stored in the start_coordinate_x, start_coordinate_y, mid_coordinate_x, mid_coordinate_y, end_coordinate_x, and end_coordinate_y columns. 9.1.3 VBStats VBStats files use only coordinates internally, and on a different native grid to the DataVolley grid. When a VBStats file is read into R using the pv_read function, these coordinates are converted to the same coordinate system used above. Each coordinate is also converted to its corresponding zone and subzone, so these are also available when using VBStats files in R, even though VBStats itself doesn’t allow scouting with zones and subzones. 9.2 Plotting by zone or subzone library(ggplot2) library(dplyr) x &lt;- dv_read(dv_example_file(1)) ## calculate attack frequency by zone, per team px &lt;- plays(x) attack_rate &lt;- px %&gt;% dplyr::filter(skill == &quot;Attack&quot;) %&gt;% group_by(team, start_zone) %&gt;% dplyr::summarize(n_attacks = n()) %&gt;% mutate(rate = n_attacks/sum(n_attacks)) %&gt;% ungroup ## add x, y coordinates associated with the zones attack_rate &lt;- cbind(attack_rate, dv_xy(attack_rate$start_zone, end = &quot;lower&quot;)) ## additionally specify the subzone to dv_xy if you want to plot by subzone (and your data ## were scouted with subzones) ## for team 2, these need to be on the top half of the diagram tm2i &lt;- attack_rate$team == teams(x)[2] attack_rate[tm2i, c(&quot;x&quot;, &quot;y&quot;)] &lt;- dv_flip_xy(attack_rate[tm2i, c(&quot;x&quot;, &quot;y&quot;)]) ggplot(attack_rate, aes(x, y, fill = rate)) + geom_tile() + ggcourt(labels = teams(x)) + scale_fill_gradient2(name = &quot;Attack rate&quot;) 9.3 Plotting by cone When scouting by cones, attacks are recorded as a direction (angle) rather than an ending point (zone or subzone). Let’s first make an attack chart of cones using arrows to indicate the direction, and varying the width and colour of the line according to the number of attacks made in each direction: x &lt;- dv_read(ovdata_example(&quot;190301_kats_beds&quot;)) px &lt;- plays(x) ## select left-side (X5) attacks attack_rate &lt;- px %&gt;% dplyr::filter(attack_code == &quot;X5&quot;) %&gt;% group_by(start_zone, end_cone) %&gt;% dplyr::summarize(n_attacks = n()) %&gt;% mutate(rate = n_attacks/sum(n_attacks)) %&gt;% ungroup ## add starting locations attack_rate &lt;- bind_cols(attack_rate, dv_xy(attack_rate$start_zone, end = &quot;lower&quot;)) ## and end locations attack_rate &lt;- bind_cols(attack_rate, dv_cone2xy(start_zones = attack_rate$start_zone, end_cones = attack_rate$end_cone, end = &quot;upper&quot;)) ggplot(attack_rate, aes(x, y, xend = ex, yend = ey, colour = rate, size = rate)) + ggcourt(labels = NULL) + geom_segment(arrow = arrow(length = unit(2, &quot;mm&quot;), type = &quot;closed&quot;, angle = 20)) + scale_colour_distiller(palette = &quot;OrRd&quot;, direction = 1, name = &quot;Attack rate&quot;) + guides(size = &quot;none&quot;) Or we can plot the cones using their polygons: cxy &lt;- dv_cone2xy(start_zones = attack_rate$start_zone, end_cones = attack_rate$end_cone, as = &quot;polygons&quot;) ## this returns coordinates as list columns, unpack these to use with ggplot ## also add an identifier for each polygon cxy &lt;- data.frame(cx = unlist(cxy$ex), cy = unlist(cxy$ey), id = unlist(lapply(seq_len(nrow(cxy)), rep, 4))) attack_rate &lt;- attack_rate %&gt;% mutate(id = row_number()) %&gt;% left_join(cxy, by = &quot;id&quot;) ggplot(attack_rate, aes(cx, cy, group = id, fill = rate)) + ggcourt(labels = NULL) + geom_polygon() + scale_fill_distiller(palette = &quot;OrRd&quot;, direction = 1, name = &quot;Attack rate&quot;) 9.4 Plotting by line segment Line segments can be used with zones/subzones, cones (as in the example above), or coordinates. ## take just the serves from the play-by-play data xserves &lt;- subset(px, skill == &quot;Serve&quot;) ## if the file had been scouted with coordinates included, we could plot them directly ## this file has no coordinates, so we&#39;ll fake some up for demo purposes coords &lt;- dv_fake_coordinates(&quot;serve&quot;, xserves$evaluation) xserves[, c(&quot;start_coordinate&quot;, &quot;start_coordinate_x&quot;, &quot;start_coordinate_y&quot;, &quot;end_coordinate&quot;, &quot;end_coordinate_x&quot;, &quot;end_coordinate_y&quot;)] &lt;- coords ## now we can plot these xserves$evaluation[!xserves$evaluation %in% c(&quot;Ace&quot;, &quot;Error&quot;)] &lt;- &quot;Other&quot; ggplot(xserves, aes(start_coordinate_x, start_coordinate_y, xend = end_coordinate_x, yend = end_coordinate_y, colour = evaluation)) + geom_segment(arrow = arrow(length = unit(2, &quot;mm&quot;), type = &quot;closed&quot;, angle = 20)) + scale_colour_manual(values = c(Ace = &quot;limegreen&quot;, Error = &quot;firebrick&quot;, Other = &quot;dodgerblue&quot;), name = &quot;Evaluation&quot;) + ggcourt(labels = c(&quot;Serving team&quot;, &quot;Receiving team&quot;)) 9.5 Heatmaps Heatmap-style plots can be generated using a kernel density estimator. This takes a discrete number of location observations and attempts to estimate their corresponding (continuous) distribution across the court. For example, take these attack ending coordinates: ggplot(px2 %&gt;% dplyr::filter(skill == &quot;Attack&quot;), aes(end_coordinate_x, end_coordinate_y)) + ggcourt(labels = NULL, court = &quot;upper&quot;) + geom_point(colour = &quot;dodgerblue&quot;) As a heatmap, using the ovlytics::ov_heatmap_kde function: library(ovlytics) ## first generate the heatmap kernel density estimate hx &lt;- ov_heatmap_kde(px2 %&gt;% dplyr::filter(skill == &quot;Attack&quot;) %&gt;% dplyr::select(end_coordinate_x, end_coordinate_y), resolution = &quot;coordinates&quot;, court = &quot;upper&quot;) ## then plot it ggplot(hx, aes(x, y, fill = density)) + scale_fill_distiller(palette = &quot;Spectral&quot;, guide = &quot;none&quot;) + geom_raster() + ggcourt(labels = NULL, court = &quot;upper&quot;) ## plot the court last, so that the lines overlay the heatmap The smoothness of the heatmap is automatically set depending on the resolution value (“subzones” or “coordinates”), but can be controlled by the bw parameter in ov_heatmap_kde if you wish to change it. You can alternatively use stat_density_2d to generate the density estimate: ggplot(px2 %&gt;% dplyr::filter(skill == &quot;Attack&quot;), aes(end_coordinate_x, end_coordinate_y)) + stat_density_2d(geom = &quot;raster&quot;, aes_string(fill = &quot;..density..&quot;), contour = FALSE, h = 0.85, n = c(60, 120)) + scale_fill_distiller(palette = &quot;Spectral&quot;, guide = &quot;none&quot;) + ggcourt(labels = NULL, court = &quot;upper&quot;) If you need more control over the heatmap, you may need to call e.g. MASS::kde2d() directly to construct the density estimate and plot it with geom_raster. 9.6 Changing direction Coordinates might not appear in the dvw file in any particular orientation (i.e. starting consistently on one side of the court). xattack &lt;- px2 %&gt;% dplyr::filter(skill == &quot;Attack&quot;) ggplot(xattack, aes(start_coordinate_x, start_coordinate_y, xend = end_coordinate_x, yend = end_coordinate_y)) + ggcourt(labels = NULL) + geom_segment(colour = &quot;dodgerblue&quot;) If we wish to plot all attacks so that they start on the same side of the court, we first need to figure out which ones need to be flipped around. The centre line of the court is at y = 3.5, so we can find any attacks that start on the upper side: toflip &lt;- which(xattack$start_coordinate_y &gt; 3.5) And then flip just those attacks so that they start on the lower half of the court: xattack$start_coordinate_x[toflip] &lt;- dv_flip_x(xattack$start_coordinate_x[toflip]) xattack$start_coordinate_y[toflip] &lt;- dv_flip_y(xattack$start_coordinate_y[toflip]) xattack$mid_coordinate_x[toflip] &lt;- dv_flip_x(xattack$mid_coordinate_x[toflip]) xattack$mid_coordinate_y[toflip] &lt;- dv_flip_y(xattack$mid_coordinate_y[toflip]) xattack$end_coordinate_x[toflip] &lt;- dv_flip_x(xattack$end_coordinate_x[toflip]) xattack$end_coordinate_y[toflip] &lt;- dv_flip_y(xattack$end_coordinate_y[toflip]) Or a little more succinctly using dplyr functions: xattack[toflip, ] &lt;- xattack[toflip, ] %&gt;% mutate(across(all_of(c(&quot;start_coordinate_x&quot;, &quot;mid_coordinate_x&quot;, &quot;end_coordinate_x&quot;)), dv_flip_x), across(all_of(c(&quot;start_coordinate_y&quot;, &quot;mid_coordinate_y&quot;, &quot;end_coordinate_y&quot;)), dv_flip_y)) Now plot it: ggplot(xattack, aes(start_coordinate_x, start_coordinate_y, xend = end_coordinate_x, yend = end_coordinate_y)) + ggcourt(labels = NULL) + geom_segment(colour = &quot;dodgerblue&quot;) 9.7 Plotting mid-coordinates The mid coordinates can be used by the scout to indicate e.g. an attack that deflected off the block. In these cases, it can be misleading to plot just the start and end locations connected by a straight line segment. Consider an attack that came off the block and went back into the attacker’s court — by plotting just the start and end points it would appear to go directly backwards. ## example data px2 &lt;- data.frame(start_coordinate_x = c(0.75, 0.8), start_coordinate_y = c(3.25, 3.25), mid_coordinate_x = c(NA, 1.4), mid_coordinate_y = c(NA, 3.5), end_coordinate_x = c(1.1, 2), end_coordinate_y = c(5.5, 1.5)) ggplot(px2, aes(start_coordinate_x, start_coordinate_y, xend = end_coordinate_x, yend = end_coordinate_y)) + ggcourt(labels = NULL) + geom_segment(colour = &quot;dodgerblue&quot;, arrow = arrow(length = unit(2, &quot;mm&quot;), type = &quot;closed&quot;, angle = 20, ends = &quot;last&quot;)) In these cases it is better to plot the mid point as well, but we need to cope with the fact that some mid-coordinates will be missing (NA): ggplot(px2, aes(start_coordinate_x, start_coordinate_y, xend = end_coordinate_x, yend = end_coordinate_y)) + ggcourt(labels = NULL) + ## lines with no midpoint geom_segment(data = px2[is.na(px2$mid_coordinate_x), ], colour = &quot;dodgerblue&quot;, arrow = arrow(length = unit(2, &quot;mm&quot;), type = &quot;closed&quot;, angle = 20, ends = &quot;last&quot;)) + ## start to mid for lines with midpoint, no ending arrow geom_segment(data = px2[!is.na(px2$mid_coordinate_x), ], aes(xend = mid_coordinate_x, yend = mid_coordinate_y), colour = &quot;dodgerblue&quot;) + ## mid to end for lines with midpoint geom_segment(data = px2[!is.na(px2$mid_coordinate_x), ], aes(x = mid_coordinate_x, y = mid_coordinate_y), colour = &quot;dodgerblue&quot;, arrow = arrow(length = unit(2, &quot;mm&quot;), type = &quot;closed&quot;, angle = 20, ends = &quot;last&quot;)) "],["live-scouting.html", "10 Live scouting 10.1 Shiny on the scout laptop 10.2 Shiny on the bench laptop 10.3 Send the file via the internet", " 10 Live scouting Most of the popular scouting software packages (DataVolley, Volley Station, etc) provide their own mechanism for connecting to live-scouted data, so that the coach or bench staff can get statistics and other information while the game is in progress. We can do the same by taking advantage of the safety scout file. This is a copy of the scout file that is automatically saved by the scouting software after each rally. There are several ways we could provide this data to our bench, in each case assuming that we will use a Shiny app that reads the scout file and produces the information that the bench staff will see. 10.1 Shiny on the scout laptop The first option is to run a Shiny app directly on the scout’s laptop. The server code of this app can read the contents of the scout safety file directly from wherever it is being saved. It would need to be re-read regularly to catch any updates (you could prevent unnecessary re-reads by using e.g. the digest::digest() function to determine if the file had actually changed since the last time it was read, or actively watch for changes in the file using the testthat::watch() function). The bench staff would then connect directly to the Shiny app using a browser on whatever device they prefer (they will need to know the IP address of the scout laptop and the port that Shiny is using. Note also that you will need to start the Shiny app on the scout laptop using host = \"0.0.0.0\" (e.g. runApp(..., host = \"0.0.0.0\")) in order to allow other clients to connect to it. 10.2 Shiny on the bench laptop Maybe your scout laptop is a bit under-powered and isn’t really coping with running Shiny as well as the scouting software. Or maybe you have multiple clients that want to connect, and performance is not great (remember that Shiny is single-threaded, so a long-running computation for one client can cause other clients to hang until it completes). So an alternative could be to send the file from the scout laptop, and run Shiny on another machine elsewhere such as the bench laptop. We can do this by running a web server on the scout laptop (you still need R installed on the scout laptop, but this script is not particularly resource-intensive so it should not slow the scout laptop down too much). Run this on the scout laptop: ## configuration safety_scout_file &lt;- &quot;E:/path/to/scoutfile.dvw&quot; ## the path to your safety scout file port &lt;- 8081 ## only need to change this if some other process is using this port ## we want the file to always be exposed under a reasonably consistent URL, so that it&#39;s easier for the bench laptop to connect ## we can assume that only one file will be served from the scout&#39;s laptop at any one time ## so we use http://IPADDRESS:PORT/live as the URL, where IPADDRESS is the IP address of the scout laptop, and PORT is defined below library(getip) library(httpuv) scout_dir &lt;- dirname(normalizePath(safety_scout_file)) ## the directory containing the scout file ## start webserver srv &lt;- startServer(host = &quot;0.0.0.0&quot;, port = port, app = list( call = function(req) { if (grepl(&quot;/live/?&quot;, req$PATH_INFO)) { ## read the file as raw bytes, to (hopefully) avoid text encoding issues that we might encounter if we read as text body &lt;- readBin(safety_scout_file, what = &quot;raw&quot;, n = file.size(safety_scout_file) * 1.2) ## the headers here don&#39;t matter if we are going to download the file via another R process, but set them anyway ## so that e.g. browser-based download will behave better list(status = 200L, headers = list(&quot;Content-Type&quot; = paste0(&quot;application/&quot;, tools::file_ext(safety_scout_file)), &quot;Content-Disposition&quot; = paste0(&quot;attachment; filename=\\&quot;&quot;, basename(safety_scout_file), &quot;\\&quot;&quot;)), body = body) } else { list(status = 404L, headers = list(&quot;Content-Type&quot; = &quot;text/plain&quot;), body = &quot;404 Not Found\\n&quot;) } } )) message(&quot;Use `srv$stop()` to stop the web server, or just exit the R session.\\n\\n&quot;, &quot;The safety scout file URL is: http://IPADDRESS:&quot;, port, &quot;/live&quot;, &quot; where IPADDRESS is the IP address of this computer.\\n&quot;, &quot;Your IP address might be &quot;, getip(), &quot;, so you can try:\\n\\n&quot;, &quot;http://&quot;, getip(), &quot;:&quot;, port, &quot;/live\\n\\n&quot;, &quot;from the bench laptop, but this IP identification method might not be reliable if you have multiple network interfaces.\\n&quot;, &quot;Use e.g. the `ipconfig` (on Windows) or `ifconfig` (Linux) system command to see all of your network interfaces and their IP addresses.&quot;) Then on the bench laptop, to download and read that file in an R script or Shiny app: tf &lt;- tempfile(fileext = &quot;.dvw&quot;) download.file(&quot;http://IPADDRESS:8081/live&quot;, destfile = tf) library(datavolley) x &lt;- dv_read(tf) Note that the server (on the scout laptop) isn’t pushing the file when it changes, it’s just sending whatever the latest file version is on each request. In your bench Shiny app, either automatically re-retrieve the file every now and again, or have a refresh button that allows the user to re-download the file and update the app content. 10.3 Send the file via the internet The two options above use a direct connection between the scout laptop and the bench device. There is no need to be connected to the internet, but at the same time you do need to have both machines on the same private network and to know the IP address of the scout laptop. However, if you have internet access, the scout file can be transferred via the internet, meaning that you don’t need to set up a private network at the venue and with the bonus that live stats can be generated anywhere in the world. Science Untangled have written a file sender app to do this — you run it on the scout laptop, pointing it at your safety scout file and each time the file changes it will be uploaded to the getpantry.cloud site. A Shiny app on the bench laptop (or anywhere else in the world) can then pull the file down and generate whatever content you want from it. That file sender app is not written in R — it’s a standalone Rust app with installers for Mac/Windows/Linux, so it’s much smaller than installing R on the scout laptop. It’s open source and so you can inspect and modify the code if you wish. See the README for further info: https://github.com/scienceuntangled/file_sender and the releases page for the installers: https://github.com/scienceuntangled/file_sender/releases. "],["odds-and-ends.html", "11 Odds and ends", " 11 Odds and ends To be moved elsewhere in the document … Counting the number of sets played by a team px %&gt;% dplyr::filter(!is.na(team)) %&gt;% distinct(team, match_id, set_number) %&gt;% count(team) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
